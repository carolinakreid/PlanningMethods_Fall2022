{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2: Basic Python Programming Skills\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The goals for today's lab are to work through some basic features of Python programming.  There is SO much to learn, and so many ways of doing the same thing but with different codes, that we're going to focus on the basics for inferential data analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Python Difference\n",
    "\n",
    "One of the challenging things about using open source technologies is that it is rarely presented as a \"complete\" software package.  If you're working in Excel, you don't need to go outside of the program to insert a \"square root of the sum of squares\" equation, for example.  It's a function in Excel. With open source software, different functions are created by different programmers, and we often have to \"call\" in that external program to do what we want. These are called libraries.\n",
    "\n",
    "Some important libraries in Python are:\n",
    "\n",
    ">**numpy**: used for math and logic operations.\n",
    "\n",
    ">**pandas**: used for the storing and basic handling of data.\n",
    "\n",
    ">**matplotlib**: used for data visualization, creating plots, graphs, etc.\n",
    "\n",
    ">**math**: from datascience, a collection of math functions\n",
    "\n",
    "We install these libraries with the following commands. The abbreviation will be what we use to \"call\" functions that belong to that library.  As we start to get more sophisticated, we'll call ever more libraries into our Python notebooks. \n",
    "\n",
    "### NOTE: If you are working in the desktop version of Python, you will have to install the libraries first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from datascience import *\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Introduction to Tables\n",
    "\n",
    "A table is a fundamental object type for representing data sets. In Python, tables are presented as a collection of ***arrays***, with each array describing a different attribute for every observation in a dataset. \n",
    "\n",
    "Concretely, an array is a **collection of values of the same type**, like a column in an Excel spreadsheet. \n",
    "\n",
    "<img src=\"excel_array.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tell Python to make an array object, and then manipulate that array by multiplying by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=make_array(1, 2, 10, 1000)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2=array*100\n",
    "array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 PANDAS\n",
    "\n",
    "<img src=\"panda.jpeg\" width=\"300\">\n",
    "\n",
    "No, not those pandas.  In Python, the word \"panda\" is derived from the term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for the same individuals. With pandas, we can clean, transform and analyze our data.  While computer programmers often work with other forms of data, when we are doing planning data analysis, we are almost always working in pandas.\n",
    "\n",
    "The building block of pandas are \"series\" - a one-dimensional labeled indexed array.  A dataframe is a multi-dimensional table made up of a collection of series.\n",
    "\n",
    "<img src=\"Series.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's add some data.  In this cell, I've a) created an array called \"data\"\n",
    "# b) set up two series (apples and oranges)\n",
    "# and c) assigned 4 values to each series\n",
    "data = {\n",
    "    'apples': [3, 2, 0, 1], \n",
    "    'oranges': [0, 3, 7, 2]\n",
    "}\n",
    "#in this next line, I'm telling Python to print the object I've created\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, I'm going to assign that array of values to a dataframe.\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note how Python has indexed my values - you can think of a dataframe as an Excel worksheet.  Just like Excel, it is assigning row numbers to each observation, but in this case, the row numbers start with 0 rather than 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Bringing a CSV file into Python\n",
    "\n",
    "Python can read in multiple forms of data, but the most common is a .csv file (\"comma separated values\").  We can easily import .csv data into Python.  The \".pd\" tells Python to call up the panda function (this is like vocabulary - something to learn), to read the file as a csv, the name of the file, and that the delimiter is a comma. (A delimiter is what separates each of the columns, or array values, from one another.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('CHISextract2018.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, all we've done is read the .csv, but what we want is to bring the data into Python so we can manipulate the columns. Similar to an Excel worksheet, pandas calls this database a \"dataframe\". Programmers often use df to signal that the data are in a dataframe - we're going to follow this convention, and assign our .csv the name \"chis_df\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df = pd.read_csv('CHISextract2018.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's take a look at our data\n",
    "chis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can get information about our dataset by calling the \"info()\" function\n",
    "chis_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Renaming Columns\n",
    "\n",
    "Great, now we have our data in Python.  The first step of any project involving disaggregate data is learning a bit more about each of our variables.  It can also be helpful to rename columns, so we don't have to keep referring to the codebook for unique numbers.  Here is a minicodebook for the data for today:\n",
    "\n",
    "> AC46: Number of times respondent drank sweet fruit drinks in past month\n",
    "\n",
    "> AC47: Number of times respondent drank water yesterday\n",
    "\n",
    "> AE_VEGI: Number of times respondent eats vegetables per week\n",
    "\n",
    "> AC42: Number of times respondent was able to find fresh fruits/vegetables in neighborhood\n",
    "(1=Never, 2=Sometimes, 3 = Usually, 4 = Always, 5=Doesn't eat f/v, 6: Doesn't shop for f/v, 7 Doesn't shop in neighborhood)\n",
    "\n",
    "> SRSEX: Self-reported Sex (1= Male, 2=Female)\n",
    "\n",
    "> OMBSRR_P1: Race/ethnicity\n",
    "(1=Hispanic, 2= White NH, 3=Black NH, 4=AmIndian/Alaska Native NH, 5=Asian NH, 6=Other or two or more)\n",
    "\n",
    "> POVLL: poverty level\n",
    "(1 = 0-99% FPL, 2=100-199% FPL, 3=200-299% FPL, 4=300% FPL and above)\n",
    "\n",
    "> POVGWD_P1: Family Poverty Threshold Level\n",
    "\n",
    "#### Helpful programming tip: the longer your variable names, the more likely you'll make a typo, meaning your code won't run.  Python is also CASE SENSITIVE, so whether you capitalize something matters for how Python reads it.  In renaming my columns, I try and keep my names simple and short, and don't include an capital letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df.rename(columns={\"AC47\":\"drank_water\", \n",
    "                        \"AC42\":\"nhood_fv\", \n",
    "                        \"AE_VEGI\":\"ate_fv\",\n",
    "                        \"SRSEX\": \"sex\",\n",
    "                        \"AC46\": \"drank_sweet\",\n",
    "                        \"OMBSRR_P1\": \"race_ethnicity\",\n",
    "                        \"POVGWD_P1\" : \"pov_ratio\",\n",
    "                       \"POVLL\" : \"pov_cat\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecting Rows and Columns from your Dataframe\n",
    "\n",
    "One thing I found very confusing about the Python programming language and pandas was the use of brackets and \"selecting\" data using slicing.  Let's look at some different ways of selecting rows and columns.  We can think of this as similar to when we select with columns or rows we want to work with in Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Python, when you want to select a column or row, you are going to use [] \n",
    "#to indicate your selection.\n",
    "\n",
    "print(chis_df['pov_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, however, that this just returns a single series, not a dataframe - \n",
    "#you can think of it as if took out a column of excel and pasted it as a string of numbers in a word document\n",
    "type(chis_df['pov_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is no longer a dataframe, or \"worksheet\" - it's just a list or series of numbers.  If what I really want to do is create an extract (e.g., copy the column into a new worksheet), I need to both \"slice\" the dataframe--which is also done with brackets--and then within the dataframe \"select\" the columns I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chis_df[['pov_ratio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now it's like I have a new worksheet with just poverty ratio data in it\n",
    "type(chis_df[['pov_ratio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On your own: try to create a new dataframe with just the poverty ratio and sex variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 .loc and .query Functions \n",
    "\n",
    "The approach above works great when all you want to do is select specific variables to work with.  But often, we want to filter our data.  For example, I might want to take a national dataset and only select counties or observations in California, or maybe I want to focus on people who ride their bicycle.\n",
    "\n",
    "There are a number of different ways of selecting data using conditional statements in Python, with the most common being .loc, .iloc, and .query.  We are not going to go over the \"iloc\" command in this class - it works using the integer location of the row and column numbers, and can easily lead to mistakes by accidentally selecting the wrong column or row. Let's just take a quick look at the .loc and .query functions - we'll come back to these next week as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The simplest use of .loc is if you want to just look at a smaller slice of your data.\n",
    "#In this case, I'm saying take the CHIS dataframe, and \"locate\" the data that is in rows 0 - 10, and in the column labeled \"sex\"\n",
    "chis_df.loc[0:10, \"sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's say I want to create a new dataframe, keeping only those responses for females\n",
    "# Note the double == sign.  \n",
    "female=chis_df.loc[chis_df[\"sex\"]==2]\n",
    "female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try on your own to create a new dataframe that only selects people who drink 8 glasses of water a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query does the same thing, but I find it more intuitive\n",
    "eight=chis_df.query('drank_water==8')\n",
    "eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On your own: create a new dataframe that only includes Hispanic hoouseholds who drank at least 8 glasses of water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploring Variables\n",
    "\n",
    "Okay!  Now let's start exploring each the variables in the dataset. A nice way to begin is to use the \"describe\" function to look at the distribution of our variables.  Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Numeric variables\n",
    "\n",
    "Numeric variables refer to any variable that includes numbers, either integers (1, 4, 300) or floats (1.6, 4.56, 300.1543). When we work with raw numeric data, we want to explore their \"distribution\" - what is the mean and standard deviation?  What is the smallest value?  What is the largest value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just as with the describe function above, we can ask to describe a single variable\n",
    "chis_df['drank_water'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I really like looking at the distribution of my variable visually - it helps me see what's going on. \n",
    "#Histograms are a powerful way of assessing the distribution of a numeric variable\n",
    "\n",
    "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
    "sns.distplot(\n",
    "    chis_df['drank_water'], norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n",
    ").set(xlabel='drank_water', ylabel='Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On your own:  make a plot of the number of times respondents ate fresh fruits and vegetables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because there aren't too many discrete values, we can also just plot the full range of answers\n",
    "sns.countplot(chis_df['drank_water']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.2 Nominal Binary variables\n",
    "\n",
    "In addition to numeric variables, we also often have to work with \"nominal\" variables (those with a \"Name\").  Note that in the CHIS data, the variables that are nominal (e.g. sex, race/ethnicity) are actually assigned number values rather than strings.   \n",
    "\n",
    "Let's start with looking at the \"sex\" variable.  It has two possible values, \"Male\" and \"Female\".  This is known as a binary or dichotomous variable.  But, even though they are represented by the numbers 1 and 2, we can't treat them as numbers - e.g., adding 2 males together doesn't give us a female.\n",
    "\n",
    "    SRSEX: Self-reported Sex (1= Male, 2=Female)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df[[\"sex\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A simple way to look the distribution of a binary variable is to request the value_counts()\n",
    "chis_df[['sex']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#another approach is to use the \"crosstab\" function available in pandas.  We'll be using crosstabs a lot when we do ttests,\n",
    "#so let's look at a simple example for now\n",
    "pd.crosstab(index=chis_df['sex'], columns=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also use the plot function above to look at the distribution visually\n",
    "sns.countplot(chis_df['sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Categorical variables\n",
    "\n",
    "A more complicated type of \"nominal\" variable is one where we have more than 2 categories - we find these all the time in planning surveys!  (And most are ordinal, meaning that the numbers assigned move either up or down in some logical way.)\n",
    "\n",
    "    nhood_fv: Number of times respondent was able to find fresh fruits/vegetables in neighborhood\n",
    "    (1=Never, 2=Sometimes, 3 = Usually, 4 = Always, 5=Doesn't eat f/v, 6: Doesn't shop for f/v, 7 Doesn't shop in neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=chis_df['nhood_fv'], columns=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(chis_df['nhood_fv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great work!!!  Explore some of the other variables on your own!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from scipy import ndimage\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real(ish) World Example\n",
    "#### Creating a active transit priority index for Oakland\n",
    "\n",
    "Please borrow and improve on the code! <br>\n",
    "It is set up to run with minimal input from the user. <br>\n",
    "It uses census shapefiles, crash data from TIMS, and census demographic information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Geography for Analysis\n",
    "\n",
    "Start by selecting the spatial information for the Census block group. <br>\n",
    "Start by Downloading Geography <br>\n",
    "Files are from Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_places = gpd.read_file(\"Spatial Files/tl_2019_06_place.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by selecting Oakland from places file using name\n",
    "\n",
    "place = census_places[census_places['NAME'] == 'Oakland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this code, we use the overlay function to select only for Census Block groups inside of Oakland, and create a new shapefile.\n",
    "#We're not going to run this today because it takes a long time to process\n",
    "#block_gr = gpd.read_file(\"Spatial Files/AlamedaBlocks.shp\")\n",
    "#bl_gr = gpd.overlay(place, block_gr, how = \"intersection\")\n",
    "#bl_gr.to_file('OaklandBlocks.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll read in the block group file created by the cell above. GeoID_2 represents the block group code\n",
    "bl_gr = gpd.read_file(\"Spatial Files/OaklandBlocks.shp\")\n",
    "bl_gr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simple copy of the bl_gr file that retains id and geography\n",
    "\n",
    "bl_simp = bl_gr[['GEOID_2','geometry']].reset_index()\n",
    "place_simp = place[['NAME','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what we have\n",
    "\n",
    "bl_simp.plot(figsize = (5, 5), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.5).set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the ugly hanging Tract that is entirely in the bay.\n",
    "# I identified it by fiding the tract with the most water in it\n",
    "bl_simp = bl_simp[bl_simp['GEOID_2'] != '060019900000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_simp.plot(figsize = (5, 5), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.5).set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach Geospatial Data - Ped and Bike Crashes\n",
    "This part of the code loads and cleans crash data from TIMS. <br>\n",
    "The crashes are for 5 years of data for Oakland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_cr = gpd.read_file(\"Spatial Files/oakland_ped_collisions.shp\")\n",
    "bike_cr = gpd.read_file(\"Spatial Files/oakland_bike_collisions.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller simpler dataframe\n",
    "# Saving Case_ID, Crash Severity, and geometry\n",
    "# Crash severity is in the column labelled \"COLLISIO_1\n",
    "\n",
    "ped_cr_sh = ped_cr[['CASE_ID','COLLISIO_1','geometry']]\n",
    "ped_cr_sh = ped_cr_sh.rename(columns={\"CASE_ID\": \"ped_ID\", \"COLLISIO_1\": \"ped_sev\"})\n",
    "ped_cr_sh['count_ped'] = 1\n",
    "bike_cr_sh = bike_cr[['CASE_ID','COLLISIO_1','geometry']]\n",
    "bike_cr_sh = bike_cr_sh.rename(columns={\"CASE_ID\": \"bike_ID\", \"COLLISIO_1\": \"bike_sev\"})\n",
    "bike_cr_sh['count_bike'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The block data didn't have a projection associated with it, let's add the projection used by the census\n",
    "bl_simp.crs = {'init' :'epsg:4326'}\n",
    "bl_simp.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject census block group data into the same projection as the pedestrian and bike crash data\n",
    "bl_proj = bl_simp.to_crs(ped_cr_sh.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing for the place shapefile\n",
    "place_simp.crs = {'init' :'epsg:4326'}\n",
    "place_proj = place_simp.to_crs(ped_cr_sh.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove crashes that are outside of Oaklands borders\n",
    "bike_cr_sh = gpd.sjoin(bike_cr_sh, place_proj, how = 'inner').drop(columns = ['NAME','index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove crashes that are outside of Oaklands borders\n",
    "\n",
    "ped_cr_sh = gpd.sjoin(ped_cr_sh, place_proj, how = 'inner').drop(columns = ['NAME','index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot what we have\n",
    "\n",
    "base = bl_proj.plot(figsize = (10, 10), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.5)\n",
    "ped_cr_sh.plot(ax =base, markersize=4, color = 'Blue')\n",
    "bike_cr_sh.plot(ax =base, markersize=2, color = 'Purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTION STEP - 1\n",
    "#### Determine Distance Consideration\n",
    "How close should a crash be to a block group to be considered an impact on residents?<br/>\n",
    "We can use buffering to change the area under consideration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at the CRS to determine the projection being used and the scale for measurements.\n",
    "# We are using us-ft. See: http://prj2epsg.org/epsg/2227\n",
    "\n",
    "ped_cr_sh.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACTION STEP IS HERE\n",
    "How close to a block group should be a crash be for us to consider it\n",
    "an impact on them? <br>\n",
    "You decide? (Remember we are measuring in feet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_buffer = 5280/4  # Quarter mile\n",
    "bike_buffer = (5280) # Mile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_cr_sh['geometry'] = ped_cr_sh['geometry'].buffer(ped_buffer)\n",
    "bike_cr_sh['geometry'] = bike_cr_sh['geometry'].buffer(bike_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what we created\n",
    "# Circles show the \"influence\" areas for crashes\n",
    "# Alpha - use for creating transparency\n",
    "\n",
    "ax = bl_proj.plot(figsize = (10, 10), color = \"whitesmoke\", edgecolor = \"lightgrey\", linewidth = 0.1)\n",
    "ax = bike_cr_sh.plot(ax =ax, facecolor = \"none\", edgecolor = \"Purple\", alpha = 0.1)\n",
    "ped_cr_sh.plot(ax =ax, facecolor = \"none\", edgecolor = \"Blue\", alpha = 0.1).set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTION STEP - 2\n",
    "#### Weight crashes by severity\n",
    "We are now going to create a metric based on the severity of the crashes. <br>\n",
    "How should we compare more or less severe crashes. Not all crashes are equal <br>\n",
    "but how should we compare them to create a composite score?\n",
    "\n",
    "There are four types of severities in the dataset (note Property Damage Only crashes are not included)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What severity should be given to each crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You decide... the default gives fatal and severe crashes five times as much weight.\n",
    "\n",
    "fatal = 5\n",
    "severe = 5\n",
    "visible = 1\n",
    "comp_pain = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can ignore this part of the code if you would like...\n",
    "It is creating the weighted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code adds a severity weight column\n",
    "\n",
    "ped_cr_sh['p_sev_wt'] = 1\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 1] = fatal\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 2] = severe\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 3] = visible\n",
    "ped_cr_sh['p_sev_wt'][ped_cr_sh['ped_sev'] == 4] = comp_pain\n",
    "\n",
    "bike_cr_sh['b_sev_wt'] = 1\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 1] = fatal\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 2] = severe\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 3] = visible\n",
    "bike_cr_sh['b_sev_wt'][bike_cr_sh['bike_sev'] == 4] = comp_pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join crashes to block groups. Sjoin will create a location record for each overlap of a crash buffer and the block group\n",
    "\n",
    "bl_ped = gpd.sjoin(bl_proj, ped_cr_sh, how = 'left').drop(columns = ['index_right'])\n",
    "bl_bike = gpd.sjoin(bl_proj, bike_cr_sh, how = 'left').drop(columns = ['index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes the data into tables organized by block group.\n",
    "\n",
    "bl_sum_ped = bl_ped.groupby(['GEOID_2'])['count_ped','p_sev_wt'].sum().reset_index()\n",
    "bl_sum_bike = bl_bike.groupby(['GEOID_2'])['count_bike','b_sev_wt'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins the data into a single table.\n",
    "\n",
    "bl_analysis = bl_sum_ped.merge(bl_sum_bike, on = 'GEOID_2')\n",
    "bl_analysis = bl_simp.merge(bl_analysis, on = 'GEOID_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun with Maps!!!\n",
    "Python maps are not a pretty as what you can make in other programs...\n",
    "BUT you can make a lot of maps really quickly. The code below creates\n",
    "a map based on the information in each column in the list.\n",
    "Feel free to steal the code to generate your own maps.\n",
    "\n",
    "Note - Alex is running through a fancier map code that is available on the desktop version of the files.  Unfortunately, the shapefiles are too large for jupyterhub to handle, so we're simplifying here.  But you can still make fast maps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['count_ped', 'p_sev_wt','count_bike','p_sev_wt']:\n",
    "    ax = bl_analysis.plot(figsize = (10, 10), scheme = \"percentiles\", k = 6, column = x, cmap = \"BuPu\",edgecolor = \"lightgrey\", linewidth = 0.5, legend = True)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(x, fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the data\n",
    "For our purposes we will want to normalize the variables summarizing the crash data. <br>\n",
    "This will allow us to more easily factor the results into a composite index in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scores normalized as percent of highest value\n",
    "bl_analysis['c_ped_perc'] = bl_analysis['count_ped']/bl_analysis['count_ped'].max()\n",
    "bl_analysis['sev_ped_perc'] = bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max()\n",
    "bl_analysis['c_bike_perc'] = bl_analysis['count_bike']/bl_analysis['count_bike'].max()\n",
    "bl_analysis['sev_bike_perc'] = bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Census Information\n",
    "This step brings in census data that we've downloaded and done some minor \n",
    "cleaning to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.read_csv(\"alamedacounty_mostly_computed_indices.csv\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the table to our work from above based on the block group\n",
    "We've also included some work to drop columns that are not necessary to keep things more clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['join_id'] = bl_analysis['GEOID_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['join_id'] = indices['Geo_GEOID'].str[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis = bl_analysis.merge(indices, on = 'join_id').drop(columns = ['join_id', 'Geo_FIPS', 'Geo_GEOID', 'Geo_NAME', 'Geo_QName',\n",
    "       'Geo_STUSAB', 'Geo_SUMLEV', 'Geo_GEOCOMP', 'Geo_FILEID', 'Geo_LOGRECNO',\n",
    "       'Geo_US', 'Geo_REGION', 'Geo_DIVISION', 'Geo_STATECE', 'Geo_STATE',\n",
    "       'Geo_COUNTY', 'Geo_COUSUB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's look at what we have!\n",
    "We are going to use that same mapping code from before to see what the variables look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['avg.hh.size', 'coc.population', 'total.population',\n",
    "       'elderly.population', 'households', 'limited.english.households',\n",
    "       'poverty.population', 'pop.poverty.determined', 'single.parent.fam',\n",
    "       'families', 'youth.population', 'occupied.housing.units',\n",
    "       'zero.vehicle.hh', 'coc.population.pct', 'elderly.population.pct',\n",
    "       'limited.english.households.pct', 'poverty.population.pct',\n",
    "       'single.parent.fam.pct', 'youth.population.pct', 'zero.vehicle.hh.pct',\n",
    "       'coc.pop.norm', 'elderly.pop.norm', 'limited.english.households.norm',\n",
    "       'poverty.population.norm', 'single.parent.fam.norm',\n",
    "       'youth.population.norm', 'zero.vehicle.hh.norm']:\n",
    "    ax = bl_analysis.plot(figsize = (10, 10), scheme = \"percentiles\", k = 6, column = x, cmap = \"BuPu\",edgecolor = \"lightgrey\", linewidth = 0.5, legend = True)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(x, fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTION STEP - 3\n",
    "#### Where should we prioritize active transit investments?\n",
    "We have all the data. But now the hard questions... <br>\n",
    "What factors should we consider to prioritize resources? <br>\n",
    "We included three starter indices: (1) Crash Only, (2) Census Factors Only, (3) Simple All Factors.\n",
    "They are not that good. Make us something better... whatever that means. <br>\n",
    "Go down to indices 4 and 5 to start making your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index1'] = \\\n",
    "        bl_analysis['c_ped_perc'] * 1 + \\\n",
    "        bl_analysis['sev_ped_perc'] * 1 + \\\n",
    "        bl_analysis['c_bike_perc'] * 1 + \\\n",
    "        bl_analysis['sev_bike_perc'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index2'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 1 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 1 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 1 + \\\n",
    "        bl_analysis['youth.population.pct'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 1 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 1 + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 1 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 1 + \\\n",
    "        bl_analysis['youth.population.norm'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index3'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 1 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 1  + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 1 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 1 + \\\n",
    "        bl_analysis['youth.population.pct'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 1 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 1  + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 1 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 1 + \\\n",
    "        bl_analysis['youth.population.norm'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 4 + \\\n",
    "        bl_analysis['count_ped']/bl_analysis['count_ped'].max() * 2 + \\\n",
    "        bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max() * 2 + \\\n",
    "        bl_analysis['count_bike']/bl_analysis['count_bike'].max() * 2 + \\\n",
    "        bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max() * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The easiest way to make your index is to change the weighting factor already in the code\n",
    "0 is the same as deleting the factor\n",
    "And... Keep creating if we have actually left enough time for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index4'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 1 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 1  + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 1 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 1 + \\\n",
    "        bl_analysis['youth.population.pct'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 1 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 1  + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 1 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 1 + \\\n",
    "        bl_analysis['youth.population.norm'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 4 + \\\n",
    "        bl_analysis['count_ped']/bl_analysis['count_ped'].max() * 2 + \\\n",
    "        bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max() * 2 + \\\n",
    "        bl_analysis['count_bike']/bl_analysis['count_bike'].max() * 2 + \\\n",
    "        bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max() * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_analysis['index5'] = \\\n",
    "        bl_analysis['coc.population.pct'] * 1 + \\\n",
    "        bl_analysis['elderly.population.pct'] * 1  + \\\n",
    "        bl_analysis['limited.english.households.pct'] * 1 + \\\n",
    "        bl_analysis['poverty.population.pct'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.pct'] * 1 + \\\n",
    "        bl_analysis['youth.population.pct'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.pct'] * 1 + \\\n",
    "        bl_analysis['coc.pop.norm'] * 1  + \\\n",
    "        bl_analysis['elderly.pop.norm'] * 1 + \\\n",
    "        bl_analysis['limited.english.households.norm'] * 1 + \\\n",
    "        bl_analysis['poverty.population.norm'] * 1 + \\\n",
    "        bl_analysis['single.parent.fam.norm'] * 1 + \\\n",
    "        bl_analysis['youth.population.norm'] * 1 + \\\n",
    "        bl_analysis['zero.vehicle.hh.norm'] * 4 + \\\n",
    "        bl_analysis['count_ped']/bl_analysis['count_ped'].max() * 2 + \\\n",
    "        bl_analysis['p_sev_wt']/bl_analysis['p_sev_wt'].max() * 2 + \\\n",
    "        bl_analysis['count_bike']/bl_analysis['count_bike'].max() * 2 + \\\n",
    "        bl_analysis['b_sev_wt']/bl_analysis['b_sev_wt'].max() * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['index1','index2','index3']:\n",
    "    ax = bl_analysis.plot(figsize = (10, 10), column = x, cmap = \"CMRmap_r\",edgecolor = \"lightgrey\", linewidth = 0.5, legend = True)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(x, fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Action Item\n",
    "#### Share screens/indices!\n",
    "\n",
    "Does anyone want to share their index and their map?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

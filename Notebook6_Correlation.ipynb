{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6 - Correlations\n",
    "\n",
    "In this notebook, we're going to explore correlations.  We'll start with some new variables in the CHIS data - most of the CHIS data are categorical, so it's more likely you'll need to use a t-test or a Chi-Square test.  But we'll demonstrate how correlations work using the CHIS.\n",
    "\n",
    "Then, we'll look at the merged eviction and ACS data, to test whether neighborhoods with higher shares of renters with cost burdens have higher eviction rates.\n",
    "\n",
    "As with everything in Python, there are lots of different ways to do the same thing, so we're providing some basic code so you have what you need for Assignment 4.  But you may find that when you work with your own data, you'll need to explore the web for other code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Setup and Reading in our Libraries\n",
    "\n",
    "As a reminder, setup should *always* be the first step in your notebook, and you need to load these cells first whenever you open the file before running any other cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again, we are going to use the correlation function in a new library called pingouin, so I'm going to install that library\n",
    "!pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install researchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the libraries into the notebook\n",
    "import pingouin as pg\n",
    "import researchpy as rp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show our plots in the Jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Prepping our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Importing and Cleaning CHIS Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in our data \n",
    "\n",
    "chis_df = pd.read_csv('chis_extract_2022_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df.rename(columns={\"SRAGE_P1\": \"age\", \"AE_VEGI\":\"ate_veg\", 'AE_FRUIT': \"ate_fruit\",\n",
    "                        \"SRSEX\": \"sex\",\n",
    "                        \"OMBSRR_P1\": \"race_ethnicity\",\n",
    "                        \"POVLL\" : \"pov_cat\",\n",
    "                       \"AK22_P1\" : \"hh_inc\",\n",
    "                       \"AM184\": \"housing_worry\",\n",
    "                       \"CV7_1\":\"covid_lostjob\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I'm just going to keep my numeric variables \n",
    "chis_df=(chis_df[['age','ate_veg', 'ate_fruit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a minute to look at the age codebook\n",
    "<img src=\"AgeCodebook.png\" width=800 height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df = chis_df[chis_df['ate_veg'] < 71] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df = chis_df[chis_df['ate_fruit'] < 71] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because of the nature of the age data, and because I actually think the relationship between age and healthy eating\n",
    "#isn't linear, I'm going to create a dummy for people between 18 and 29\n",
    "chis_df['under30_dv']=np.where((chis_df['age']<30),1,0)\n",
    "chis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Importing and Cleaning Eviction Lab data\n",
    "First, we're going to read in our Eviction Lab data. It is publicly available here: https://data-downloads.evictionlab.org/#data-for-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is my code for reading in the complete evictions data and filtering it\n",
    "# If you are using an area outside Alameda County for your assignment, \n",
    "# you'll want to run the lines below and alter the file location and county filter.\n",
    "\n",
    "# data =  pd.read_csv('C:/Users/katea/Downloads/tract_proprietary_valid_2000_2018.csv')\n",
    "# ac_data = data[data['county']=='Alameda County']\n",
    "# ac_data.to_csv('C:/Users/katea/Downloads/AC_tract_proprietary_valid_2000_2018.csv', index = False)\n",
    "\n",
    "#today we're just going to work with the extract\n",
    "evictions00_18 = pd.read_csv('AC_tract_proprietary_valid_2000_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eviction Lab Codebook\n",
    "You can also find this information in the Excel sheet in DataHub, which I downloaded from the same link above.\n",
    "\n",
    "|variable_name  |variable_type|description                                                               |\n",
    "|---------------|-------------|--------------------------------------------------------------------------|\n",
    "|fips           |numeric      |tract fips                                                                |\n",
    "|cofips         |numeric      |county fips                                                               |\n",
    "|tract          |string       |tract name                                                                |\n",
    "|county         |string       |county name                                                               |\n",
    "|state          |string       |state name                                                                |\n",
    "|year           |numeric      |year                                                                      |\n",
    "|type           |string       |OBSERVED                                                                  |\n",
    "|filings        |numeric      |number of filings observed in proprietary data                            |\n",
    "|filing_rate    |numeric      |number of filings per 100 renting households                              |\n",
    "|threatened     |numeric      |number of households threatened with eviction observed in proprietary data|\n",
    "|threatened_rate|numeric      |number of households threatened per 100 renting households                |\n",
    "|judgements     |numeric      |number of judgements observed in proprietary data                         |\n",
    "|judgement_rate |numeric      |number of judgements per 100 renting households                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Filtering for one year (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: the year is an integer64 type, so don't put quotes around 2016!\n",
    "evictions16 = evictions00_18[evictions00_18['year'] == 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Importing and Cleaning ACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the ACS data, skipping the second header row \n",
    "# (remember, Python numbering starts at 0) when you read in the data\n",
    "acs16 = pd.read_csv(\"ACSDT5Y2016.B25070-Data.csv\", skiprows = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acs16 = acs16[['GEO_ID', 'NAME', 'B25070_001E', 'B25070_002E', 'B25070_003E',\n",
    "       'B25070_004E', 'B25070_005E', 'B25070_006E', 'B25070_007E',\n",
    "       'B25070_008E', 'B25070_009E', 'B25070_010E', 'B25070_011E']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acs16 = acs16.rename(columns = {'B25070_001E':'total', \n",
    "                        'B25070_002E':'rb_less10',\n",
    "                        'B25070_003E':'rb_10_15',\n",
    "                        'B25070_004E':'rb_15_20',\n",
    "                        'B25070_005E':'rb_20_25',\n",
    "                        'B25070_006E':'rb_25_30',\n",
    "                        'B25070_007E':'rb_30_35',\n",
    "                        'B25070_008E':'rb_35_40',\n",
    "                        'B25070_009E':'rb_40_50',\n",
    "                        'B25070_010E':'rb_50plus',\n",
    "                        'B25070_011E':'na'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rent-burdened variable as percent of total\n",
    "acs16['pct_rb30plus'] = (acs16['rb_30_35'] + acs16['rb_35_40'] + acs16['rb_40_50'] + acs16['rb_50plus'])/acs16['total']\n",
    "acs16.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing up a fips column with the right number of characters using string subsetting\n",
    "# note: ending the number 10 with a colon means we go from the 10th character to the END of the string\n",
    "acs16['fips'] = acs16['GEO_ID'].str[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#align fips datatypes\n",
    "evictions16['fips'] = evictions16['fips'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "evict_df = acs16.merge(evictions16, on='fips', how='left', indicator=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evict_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Correlation\n",
    "\n",
    "The correlation coefficient (sometimes referred to as Pearson's correlation coefficient, Pearson's product-moment correlation, or simply r) measures the strength of the linear relationship between two variables. \n",
    "\n",
    "The correlation coefficient is directly linked to the beta coefficient in a linear regression (= the slope of a best-fit line), but has the advantage of being standardized between -1 to 1 ; the former meaning a perfect negative linear relationship, and the latter a perfect positive linear relationship. In other words, no matter what are the original units of the two variables are, the correlation coefficient will always be in the range of -1 to 1, which makes it very easy to work with.\n",
    "\n",
    "The correlation coefficient *r*\n",
    "\n",
    "> The correlation coefficient ranges from −1 to 1. A value of 1 implies that a linear equation describes the relationship between X and Y perfectly, with all data points lying on a line for which Y increases as X increases. A value of −1 implies that all data points lie on a line for which Y decreases as X increases. A value of 0 implies that there is no linear relationship between the variables. \n",
    "\n",
    "<img src=\"py-corr-1.webp\" width=800 height=400 />\n",
    "\n",
    "In hypothesis testing, you want to find not only the correlation coefficient (the r value) but also the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start by plotting the two numeric variables\n",
    "sns.regplot(chis_df[\"ate_fruit\"], chis_df[\"ate_veg\"], ci=None, scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's run our correlation test\n",
    "pg.corr(x=chis_df['ate_fruit'], y=chis_df[\"ate_veg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how about for age?\n",
    "pg.corr(x=chis_df['age'], y=chis_df[\"ate_veg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at what we find if we use the dummy instead?  What's going on?\n",
    "rp.ttest((chis_df[chis_df['under30_dv']==0].ate_veg), (chis_df[chis_df['under30_dv']==1].ate_veg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see if our hypothesis that higher rent burdens lead to higher eviction filing rates results in a statistically significant finding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evict_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(evict_df[\"filing_rate\"], evict_df[\"rb30plus\"], ci=None, scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.corr(x=evict_df['filing_rate'], y=evict_df[\"pct_rb30plus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can actually get the correlations for all the variables in your dataset,\n",
    "#known as a correlation matrix, at the same time\n",
    "corr=evict_df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and create a correlation heatmap\n",
    "# Set up the matplotlib plot configuration\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Generate a mask for upper traingle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Configure a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr, annot=True, mask = mask, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0  That's it!  \n",
    "\n",
    "You now have all the tools you need to be able to complete Assignment 4!  It's time to practice and dedicate time to pulling everything from the semester together into your final case study!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
